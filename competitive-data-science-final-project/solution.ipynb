{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have to install ipython-autotime using 'pip install ipython-autotime'\n",
    "%load_ext autotime\n",
    "\n",
    "import gc\n",
    "import IPython.display\n",
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# in this project, the metric is rmse, not mse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# SVR and KNeighborsRegressor is too slow to apply this data\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#TODO: sklearn AdaBoost, GradientBoosting 사용\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "seed = 180718\n",
    "\n",
    "# lag 양을 여기서 결정\n",
    "shift_range = [1,2,3,12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.91 s\n"
     ]
    }
   ],
   "source": [
    "sales = pd.read_csv('./dataset/sales_train.csv.gz')\n",
    "shops = pd.read_csv('./dataset/shops.csv')\n",
    "items = pd.read_csv('./dataset/items.csv')\n",
    "#item_cats = pd.read_csv('./dataset/item_categories.csv')\n",
    "test = pd.read_csv(\"./dataset/test.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define a useful function to save a memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8 ms\n"
     ]
    }
   ],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get base data form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The form should have 'shop_id', 'item_id', 'date_block_num' because the required form of this competition is 'ID' made of 'shop_id' and 'item_id', and 'item_cnt_month'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "gb = sales.groupby(index_cols, as_index=False).sum().rename(columns={'item_cnt_day':'month_sale'})\n",
    "\n",
    "del sales\n",
    "\n",
    "# 가격 정보를 사용할 것인지 아직 모름. 사용한다면 살려야 함.\n",
    "gb = gb.drop('item_price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'shop_id': np.sort(shops.shop_id.unique()), 'key':np.zeros(len(shops.shop_id.unique()))})\n",
    "df2 = pd.DataFrame({'item_id': np.sort(items.item_id.unique()), 'key':np.zeros(len(items.item_id.unique()))})\n",
    "df3 = pd.DataFrame({'date_block_num': np.sort(gb.date_block_num.unique()), 'key':np.zeros(len(gb.date_block_num.unique()))})\n",
    "\n",
    "df = df1.merge(df2).merge(df3)\n",
    "\n",
    "del df1, df2, df3, shops\n",
    "\n",
    "df = df.drop('key', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(gb, how='outer').fillna(0)\n",
    "\n",
    "del gb\n",
    "\n",
    "df.head()\n",
    "\n",
    "df = downcast_dtypes(df)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip (0, 20) before making something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.month_sale = df.month_sale.values.clip(0,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# montly sale in the shop, item, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shop_gb_sum = df.groupby(['shop_id', 'date_block_num'], as_index=False).sum()\n",
    "shop_gb_sum = shop_gb_sum.rename(columns={'month_sale':'month_sale_shop_sum'})\n",
    "shop_gb_sum = shop_gb_sum.drop(columns=['item_id'])\n",
    "\n",
    "shop_gb_mean = df.groupby(['shop_id', 'date_block_num'], as_index=False).mean()\n",
    "shop_gb_mean = shop_gb_mean.rename(columns={'month_sale':'month_sale_shop_mean'})\n",
    "shop_gb_mean = shop_gb_mean.drop(columns=['item_id'])\n",
    "\n",
    "item_gb_sum = df.groupby(['item_id', 'date_block_num'], as_index=False).sum()\n",
    "item_gb_sum = item_gb_sum.rename(columns={'month_sale':'month_sale_item_sum'})\n",
    "item_gb_sum = item_gb_sum.drop(columns=['shop_id'])\n",
    "\n",
    "item_gb_mean = df.groupby(['item_id', 'date_block_num'], as_index=False).mean()\n",
    "item_gb_mean = item_gb_mean.rename(columns={'month_sale':'month_sale_item_mean'})\n",
    "item_gb_mean = item_gb_mean.drop(columns=['shop_id'])\n",
    "\n",
    "category = items.drop(columns=['item_name'], axis=1)\n",
    "category = category.rename(columns={'item_category_id':'category_id'})\n",
    "\n",
    "item_sum_with_cat_gb = item_gb_sum.merge(category, how='left')\n",
    "\n",
    "category_gb_sum = item_sum_with_cat_gb.groupby(['category_id', 'date_block_num'], as_index=False).sum()\n",
    "category_gb_sum = category_gb_sum.rename(columns={'month_sale_item_sum':'month_sale_category_sum'})\n",
    "category_gb_sum = category_gb_sum.drop(columns=['item_id'], axis=1)\n",
    "\n",
    "category_gb_mean = item_sum_with_cat_gb.groupby(['category_id', 'date_block_num'], as_index=False).mean()\n",
    "category_gb_mean = category_gb_mean.rename(columns={'month_sale_item_sum':'month_sale_category_mean'})\n",
    "category_gb_mean = category_gb_mean.drop(columns=['item_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.merge(shop_gb_sum, how='left').fillna(0)\n",
    "df = df.merge(shop_gb_mean, how='left').fillna(0)\n",
    "\n",
    "df = df.merge(item_gb_sum, how='left').fillna(0)\n",
    "df = df.merge(item_gb_mean, how='left').fillna(0)\n",
    "\n",
    "df = df.merge(category, how='left').fillna(0)\n",
    "df = df.merge(category_gb_sum, how='left').fillna(0)\n",
    "df = df.merge(category_gb_mean, how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del shop_gb_sum, shop_gb_mean, item_gb_sum, item_gb_mean, category_gb_sum, category_gb_mean, category, item_sum_with_cat_gb, items\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# montly sale in the item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = downcast_dtypes(df)\n",
    "lag_df = df.copy()\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_cols = ['shop_id', 'item_id', 'date_block_num', 'category_id']\n",
    "\n",
    "cols_to_rename = list(lag_df.columns.difference(index_cols)) \n",
    "\n",
    "for month_shift in tqdm_notebook(shift_range):\n",
    "    train_shift = lag_df[index_cols + cols_to_rename].copy()\n",
    "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "    \n",
    "    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "    train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "    lag_df = lag_df.merge(train_shift, how='outer')\n",
    "    \n",
    "    del train_shift, foo\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이유는 모르겠는데 끝나고 나면 lag_df에서 index column들이 64비트로 변경됨\n",
    "lag_df[index_cols] = downcast_dtypes(lag_df[index_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Abort unnecessary data in lag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_df = lag_df[12 <= lag_df.date_block_num]\n",
    "lag_df = lag_df[lag_df.date_block_num <= 34]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save and Load lag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "#압축하면서 저장하는게 너무 오래걸린다. 나중에 시간 있을 때 한번 돌려보자.\n",
    "#lag_df.to_csv(\"lag_df.csv.gz\", index=False, compression='gzip')\n",
    "\n",
    "lag_df = pd.read_csv(\"lag_df.csv.gz\")\n",
    "# lag_df = downcast_dtypes(lag_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make column useful column lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.98 ms\n"
     ]
    }
   ],
   "source": [
    "dates = lag_df['date_block_num']\n",
    "fit_cols = [col for col in lag_df.columns if col[-1] in [str(item) for item in shift_range]] \n",
    "to_drop_cols = list(set(list(lag_df.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train / valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "valid_block = 33\n",
    "test_block = 34\n",
    "dates_train = dates[dates <  valid_block]\n",
    "dates_valid  = dates[dates == valid_block]\n",
    "\n",
    "X_train = lag_df.loc[dates <  valid_block].drop(to_drop_cols, axis=1)\n",
    "y_train = lag_df.loc[dates <  valid_block, 'month_sale'].values.clip(0,20)\n",
    "\n",
    "valid = lag_df.loc[dates == valid_block]\n",
    "valid = test.merge(valid, how='left').fillna(0).drop('ID', axis=1)\n",
    "X_valid =  valid.drop(to_drop_cols, axis=1)\n",
    "y_valid =  valid['month_sale'].values.clip(0,20)\n",
    "X_test = lag_df.loc[dates == test_block].drop(to_drop_cols, axis=1)\n",
    "\n",
    "#del valid, lag_df\n",
    "\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make full train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_block = 34\n",
    "\n",
    "# dates_full_train = dates[dates < test_block]\n",
    "# dates_test = dates[dates == test_block]\n",
    "\n",
    "# X_full_train = lag_df.loc[dates <  test_block].drop(to_drop_cols, axis=1)\n",
    "# y_full_train = lag_df.loc[dates <  test_block, 'month_sale'].values.clip(0,20)\n",
    "# X_test = lag_df.loc[dates == test_block].drop(to_drop_cols, axis=1)\n",
    "\n",
    "# del lag_df\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define this competition metric as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 36.9 ms\n"
     ]
    }
   ],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.clip(y_true, 0, 20), np.clip(y_pred, 0, 20)))\n",
    "\n",
    "def get_valid_rmse(reg):\n",
    "    reg.fit(X_train.values, y_train)\n",
    "    pred = reg.predict(X_valid.values)\n",
    "    return rmse(pred, y_valid)\n",
    "\n",
    "def get_valid_rmse_with_zeros(reg):\n",
    "    df = sales[['shop_id', 'item_id']]\n",
    "    df = df.merge(X_valid, how='inner')\n",
    "    df = df.drop_duplicates()\n",
    "    pred = reg.predict(df)\n",
    "    df = df[['shop_id', 'item_id']]\n",
    "    df['target'] = pred\n",
    "    f = test.merge(df, how='left').fillna(0)\n",
    "    return rmse(f.target, y_valid)\n",
    "\n",
    "def get_prediction(reg):\n",
    "    reg.fit(X_full_train.values, y_full_train)\n",
    "    pred = reg.predict(X_test.values)\n",
    "    return pred\n",
    "\n",
    "def make_submission_from_prediction(pred, filename):\n",
    "    sub = lag_df[dates == test_block]\n",
    "    sub = sub.rename(columns={'month_sale':'item_cnt_month'})\n",
    "    sub = sub[['shop_id', 'item_id', 'month_sale']]\n",
    "    make_submission(sub, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First level models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8996601485872576"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "get_valid_rmse(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 145 ms\n"
     ]
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.97 ms\n"
     ]
    }
   ],
   "source": [
    "del lag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970715380115442"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7min 24s\n"
     ]
    }
   ],
   "source": [
    "enet = ElasticNet()\n",
    "get_valid_rmse(enet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9927055249567897"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "get_valid_rmse_with_zeros(enet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8856132910508092"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "lgb = LGBMRegressor(random_state=seed)\n",
    "get_valid_rmse(lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.884203414214573"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "get_valid_rmse_with_zeros(lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8821269853328018"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1h 43min 45s\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=20, max_depth=13, random_state=seed)\n",
    "get_valid_rmse(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8796924000459201"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "get_valid_rmse_with_zeros(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(X_train.columns.values)):\n",
    "    print(str(X_train.columns.values[i]) + \": \" + str(rf.feature_importances_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(max_depth=10, learning_rate=0.03, random_state=seed)\n",
    "get_valid_rmse(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegressionression()\n",
    "pred = get_prediction(lr)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_submission_from_prediction(get_prediction(rf), 'rf_n20_m13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission_from_prediction(get_prediction(xgb), 'xgb_m10_l3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_params = {\n",
    "#                'feature_fraction': 0.75,\n",
    "#                'metric': 'rmse',\n",
    "#                'nthread':1, \n",
    "#                'min_data_in_leaf': 2**7, \n",
    "#                'bagging_fraction': 0.75, \n",
    "#                'learning_rate': 0.03, \n",
    "#                'objective': 'mse', \n",
    "#                'bagging_seed': 2**7, \n",
    "#                'num_leaves': 2**7,\n",
    "#                'bagging_freq':1,\n",
    "#                'verbose':0 \n",
    "#               }\n",
    "\n",
    "# lgb = lightgbm.train(lgb_params, lightgbm.Dataset(X_train.values, label=y_train), 100)\n",
    "# pred_lgb = lgb.predict(X_valid)\n",
    "# rmse(pred_lgb, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make utilities to submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function makes codes simple, so it's good to make these functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission_df(all_prediction):\n",
    "    df = test.merge(all_prediction, on=[\"shop_id\", \"item_id\"], how=\"left\")[[\"ID\", \"item_cnt_month\"]]\n",
    "    df[\"item_cnt_month\"] = df[\"item_cnt_month\"].fillna(0).clip(0, 20)    \n",
    "    return df\n",
    "\n",
    "def make_submission_file(df, filename):\n",
    "    df.to_csv(\"./submission/%s.csv\" % filename, index=False)\n",
    "    \n",
    "def make_submission(all_prediction, filename=\"no_name\"):\n",
    "    make_submission_file(make_submission_df(all_prediction), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell automatically submits the submission file to kaggle. However, it should be carefully executed because the submitting opportunities are limited.\n",
    "- remove '#' before submitting\n",
    "- add a meaningful message to a submission\n",
    "- my rule is using a filename for models and a message for data\n",
    "    - ex) filename: rf_n20m13.csv, message: ot-sic-sm-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c competitive-data-science-final-project -f ./submission/rf_n20_m13.csv -m \"ot-sic-sm-20\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check public score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submissions -c competitive-data-science-final-project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
