{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have to install ipython-autotime using 'pip install ipython-autotime'\n",
    "%load_ext autotime\n",
    "\n",
    "import gc\n",
    "import IPython.display\n",
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# in this project, the metric is rmse, not mse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "#SVR and KNeighborsRegressor is too slow\n",
    "#from sklearn.svm import SVR\n",
    "#from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "import lightgbm\n",
    "\n",
    "seed = 180718"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.63 s\n"
     ]
    }
   ],
   "source": [
    "sales = pd.read_csv('./dataset/sales_train.csv.gz')\n",
    "shops = pd.read_csv('./dataset/shops.csv')\n",
    "items = pd.read_csv('./dataset/items.csv')\n",
    "item_cats = pd.read_csv('./dataset/item_categories.csv')\n",
    "test = pd.read_csv(\"./dataset/test.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze raw datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start to anylyze basic information about give datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make float data looks integer data\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "\n",
    "sales.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do simple calculations here. The number of shop_id is 60, and the number of item_id is 22,170. Therefore, the total number of combinations of them is 1,330,200. However, there are only 214,200 IDs in the test. It means that this competition only requires 16.1% of the all shop_id and item_id combinations.\n",
    "\n",
    "We can use this fact in 3 ways.\n",
    "1. get a prediction of the test IDs in the submission using full data in the training and the validation.\n",
    "2. get a prediction of the test IDs in the validation and the submission using full data in the training.\n",
    "3. Reduce data before training to make training short.\n",
    "\n",
    "I think we should take 2 or 3. In the first way, the validation score can not be fitting to the test score. My strategy is using 3 till the validation and using 2 in the submission only. I think full data has other shops or other items, but it can give some information about how the price is going especially if I use RNN algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan EDA(Exploratory data analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think item_price and item_cnt_day have interesting qualtiles and min-max values. First of all, item_cnt_day must not be zero value because sales data is record of something that occured in sales. However, the target is item_cnt_month, so it would be better to analyze monthly data of item_cnt. In the item, the max price is so much higher than others. I'm not sure but, it's possible to use the extream price for prediction.\n",
    "\n",
    "My plans is as below.\n",
    "\n",
    "1. reduce data using test id combinations\n",
    "2. aggregate the total item_cnt_month of shops month by month\n",
    "3. aggregate the total item_cnt month of items month by month\n",
    "4. aggregate the total item_cnt_month month by month\n",
    "\n",
    "The purpose of them is to know if there are correlations between them and if there are patterns in time flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make utilities to submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function makes codes simple, so it's good to make these functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.67 ms\n"
     ]
    }
   ],
   "source": [
    "def make_submission_df(all_prediction):\n",
    "    df = test.merge(all_prediction, on=[\"shop_id\", \"item_id\"], how=\"left\")[[\"ID\", \"item_cnt_month\"]]\n",
    "    df[\"item_cnt_month\"] = df[\"item_cnt_month\"].fillna(0).clip(0, 20)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def make_submission_file(df, name=\"\"):\n",
    "    df.to_csv(\"./submission/%s.csv\" % name, sep=\",\", index=False)\n",
    "    \n",
    "def make_submission(all_prediction, name=\"\"):\n",
    "    make_submission_file(make_submission_df(all_prediction), name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be benchmarks to measure my prediction's quality, so I made very simple ones. I think it should be done in first phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = pd.read_csv('./dataset/sample_submission.csv.gz')\n",
    "# make_submission_file(sample, 'sample_value')\n",
    "\n",
    "# sample['item_cnt_month'] = 0\n",
    "# make_submission_file(sample, 'zero_value')\n",
    "\n",
    "# previous_month = sales[sales[\"date_block_num\"] == 33].groupby([\"shop_id\", \"item_id\"], as_index=False).item_cnt_day.sum().rename(columns={\"item_cnt_day\": \"item_cnt_month\"})\n",
    "# make_submission(previous_month, \"previous_month_value\")\n",
    "\n",
    "# del sample, previous_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sample value(all 0.5): 1.23646\n",
    "* zero value: 1.25011\n",
    "* previous month value: 1.16777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce data using test id combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_sales = sales.merge(test)\n",
    "reduced_sales = reduced_sales.drop('ID', axis=1)\n",
    "reduced_sales.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before reducing data, the total number of rows is 2,935,849. Now, the amount of data is reduced to 41.7%.\n",
    "It means that test data is not randomly picked in all combinations of shop_id and item_id.\n",
    "One of the possible scenarios is that the host of this competition chose test targets in combinations that appeared in the sales data, not in all combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze combinations of shop_id and item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comb = sales[['shop_id', 'item_id']]\n",
    "full_comb = full_comb.drop_duplicates()\n",
    "display(full_comb.describe())\n",
    "display('unique value of shop_id: ' + str(len(full_comb.shop_id.unique())))\n",
    "display('unique value of item_id: ' + str(len(full_comb.item_id.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_comb = reduced_sales[['shop_id', 'item_id']]\n",
    "reduced_comb = reduced_comb.drop_duplicates()\n",
    "display(reduced_comb.describe())\n",
    "display('unique value of shop_id: ' + str(len(reduced_comb.shop_id.unique())))\n",
    "display('unique value of item_id: ' + str(len(reduced_comb.item_id.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(test.describe())\n",
    "display('unique value of shop_id: ' + str(len(test.shop_id.unique())))\n",
    "display('unique value of item_id: ' + str(len(test.item_id.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| data | full | reduced | test |\n",
    "|------|------| ------- | ---- |\n",
    "| shop_id | 60 | 42 | 42 |\n",
    "| item_id | 21,807 | 4,716 | 5100 |\n",
    "| total | 424,124 | 111,404 | 214,200 |\n",
    "| possible | 1,308,420 | 198,072 | 214,200 |\n",
    "| ratio | 32.4% | 56.2% | 100% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target is 214,200 combination. However, in the reduced data, there is only 4,716 unique item_ids. It means that 385 item was not sold in that period. In the combination, there is more zero sold combinations. It's almost half of the test combinations. In the full data set, zero sold combination ratios is abount 1/3. This is not so big gap between them. I think the important is the number of item_id. The test unique item_id is almost 1/4 of full data item_id. If we use one hot encoding for item_id, we can use only 1/4 of memory.\n",
    "\n",
    "I focused on something else. The total number of the combinations in the test is 214,200, but 111,404 in the reduced dataset. It means that only about half of combinations exists in sales data. One more data selection options is selecting only data in 111,404 combinations. I'm going to use the test dataset first, and then I'll use smaller and bigger one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del full_comb, reduced_comb, reduced_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get applicable dataset to models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define a useful function to save a memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.5 ms\n"
     ]
    }
   ],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get base data form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The form should have 'shop_id', 'item_id', 'date_block_num' because the required form of this competition is 'ID' made of 'shop_id' and 'item_id', and 'item_cnt_month'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.24 ms\n"
     ]
    }
   ],
   "source": [
    "index_cols = ['shop_id', 'item_id', 'date_block_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "gb = sales.groupby(index_cols, as_index=False).sum().rename(columns={'item_cnt_day':'month_sale'})\n",
    "# 가격 정보를 사용할 것인지 아직 모름. 사용한다면 살려야 함.\n",
    "gb = gb.drop('item_price', axis=1)\n",
    "\n",
    "df1 = pd.DataFrame({'shop_id': np.sort(shops.shop_id.unique()), 'key':np.zeros(len(shops.shop_id.unique()))})\n",
    "df2 = pd.DataFrame({'item_id': np.sort(items.item_id.unique()), 'key':np.zeros(len(items.item_id.unique()))})\n",
    "df3 = pd.DataFrame({'date_block_num': np.sort(gb.date_block_num.unique()), 'key':np.zeros(len(gb.date_block_num.unique()))})\n",
    "\n",
    "df = df1.merge(df2).merge(df3)\n",
    "\n",
    "del df1, df2, df3\n",
    "\n",
    "df = df.drop('key', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.5 s\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(gb, how='outer').fillna(0)\n",
    "\n",
    "del gb\n",
    "\n",
    "df.head()\n",
    "\n",
    "df = downcast_dtypes(df)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.3f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip (0, 20) before making something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 378 ms\n"
     ]
    }
   ],
   "source": [
    "df.month_sale = df.month_sale.values.clip(0,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# montly sale in the shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>month_sale_shop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  date_block_num  month_sale_shop\n",
       "0        0               0           5411.0\n",
       "1        0               1           5820.0\n",
       "2        0               2              0.0\n",
       "3        0               3              0.0\n",
       "4        0               4              0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.48 s\n"
     ]
    }
   ],
   "source": [
    "shop_gb = df.groupby(['shop_id', 'date_block_num'], as_index=False).sum()\n",
    "shop_gb = shop_gb.rename(columns={'month_sale':'month_sale_shop'})\n",
    "shop_gb = shop_gb.drop(columns=['item_id'])\n",
    "shop_gb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>month_sale_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  date_block_num  month_sale_item\n",
       "0        0               0              0.0\n",
       "1        0               1              0.0\n",
       "2        0               2              0.0\n",
       "3        0               3              0.0\n",
       "4        0               4              0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.65 s\n"
     ]
    }
   ],
   "source": [
    "# 총합을 주는게 좋을까 전체 샵의 수로 나누는게 좋을까? 샵에 대해서는 어쩔까?\n",
    "item_gb = df.groupby(['item_id', 'date_block_num'], as_index=False).sum()\n",
    "item_gb = item_gb.rename(columns={'month_sale':'month_sale_item'})\n",
    "item_gb = item_gb.drop(columns=['shop_id'])\n",
    "item_gb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>month_sale</th>\n",
       "      <th>month_sale_shop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num  month_sale  month_sale_shop\n",
       "0        0        0               0         0.0           5411.0\n",
       "1        0        0               1         0.0           5820.0\n",
       "2        0        0               2         0.0              0.0\n",
       "3        0        0               3         0.0              0.0\n",
       "4        0        0               4         0.0              0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.46 s\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(shop_gb, how='left').fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>month_sale</th>\n",
       "      <th>month_sale_shop</th>\n",
       "      <th>month_sale_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5411.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5820.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num  month_sale  month_sale_shop  \\\n",
       "0        0        0               0         0.0           5411.0   \n",
       "1        0        0               1         0.0           5820.0   \n",
       "2        0        0               2         0.0              0.0   \n",
       "3        0        0               3         0.0              0.0   \n",
       "4        0        0               4         0.0              0.0   \n",
       "\n",
       "   month_sale_item  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(item_gb, how='left').fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# montly sale in the item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.63 ms\n"
     ]
    }
   ],
   "source": [
    "#12개월 전체를 할 수도 있고 일부를 할 수도 있다. 난 여기서 일부만 사용\n",
    "#ensembling에선 1~5,12를 사용\n",
    "\n",
    "shift_range = [1,2,3,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16017cdea964cb8801876320b670466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "# List of columns that we will use to create lags\n",
    "cols_to_rename = list(df.columns.difference(index_cols)) \n",
    "\n",
    "lag_df = df\n",
    "\n",
    "for month_shift in tqdm_notebook(shift_range):\n",
    "    train_shift = lag_df[index_cols + cols_to_rename].copy()\n",
    "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "    \n",
    "    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "    train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "    lag_df = lag_df.merge(train_shift, how='outer')\n",
    "    del train_shift\n",
    "    lag_df = downcast_dtypes(lag_df)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 작업이 시간이 오래걸리므로 csv나 npy파일로 만든 후에 저장했다가 부르는건 어떨까?\n",
    "- validation용 traing set과 test용 traing set을 분리시킨 후에 파이프 라인을 만들어서 코드를 깔끔하게 만들자\n",
    "- 작업이 끝나면 Knn feature와 mean encoding 방법을 적용할 방법을 생각해보자\n",
    "- 마지막은 ensemble을 해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Trim lag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26.3 s\n"
     ]
    }
   ],
   "source": [
    "# Don't use old data from year 2013(because we use 12 months lag data in the target)\n",
    "# to make submission 33 -> 34\n",
    "\n",
    "valid_last = 33\n",
    "test_last = 34\n",
    "\n",
    "lag_df = lag_df[12 <= lag_df.date_block_num]\n",
    "lag_df = lag_df[lag_df.date_block_num <= test_last]\n",
    "lag_df = lag_df.fillna(0)\n",
    "lag_df = downcast_dtypes(lag_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save lag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.4 ms\n"
     ]
    }
   ],
   "source": [
    "# lag_df.to_csv(\"full_lag_df.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. load lag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.28 ms\n"
     ]
    }
   ],
   "source": [
    "# lag_df = pd.read_csv(\"full_lag_df.csv\")\n",
    "# lag_df = downcast_dtypes(lag_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.3 ms\n"
     ]
    }
   ],
   "source": [
    "#shift_range = [1,2,3,12]\n",
    "# List of all lagged features\n",
    "fit_cols = [col for col in lag_df.columns if col[-1] in [str(item) for item in shift_range]] \n",
    "# We will drop these at fitting stage\n",
    "to_drop_cols = list(set(list(lag_df.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>month_sale</th>\n",
       "      <th>month_sale_shop</th>\n",
       "      <th>month_sale_item</th>\n",
       "      <th>month_sale_lag_1</th>\n",
       "      <th>month_sale_item_lag_1</th>\n",
       "      <th>month_sale_shop_lag_1</th>\n",
       "      <th>month_sale_lag_2</th>\n",
       "      <th>month_sale_item_lag_2</th>\n",
       "      <th>month_sale_shop_lag_2</th>\n",
       "      <th>month_sale_lag_3</th>\n",
       "      <th>month_sale_item_lag_3</th>\n",
       "      <th>month_sale_shop_lag_3</th>\n",
       "      <th>month_sale_lag_12</th>\n",
       "      <th>month_sale_item_lag_12</th>\n",
       "      <th>month_sale_shop_lag_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    shop_id  item_id  date_block_num  month_sale  month_sale_shop  \\\n",
       "12        0        0              12         0.0              0.0   \n",
       "13        0        0              13         0.0              0.0   \n",
       "14        0        0              14         0.0              0.0   \n",
       "15        0        0              15         0.0              0.0   \n",
       "16        0        0              16         0.0              0.0   \n",
       "\n",
       "    month_sale_item  month_sale_lag_1  month_sale_item_lag_1  \\\n",
       "12              0.0               0.0                    0.0   \n",
       "13              0.0               0.0                    0.0   \n",
       "14              0.0               0.0                    0.0   \n",
       "15              0.0               0.0                    0.0   \n",
       "16              0.0               0.0                    0.0   \n",
       "\n",
       "    month_sale_shop_lag_1  month_sale_lag_2  month_sale_item_lag_2  \\\n",
       "12                    0.0               0.0                    0.0   \n",
       "13                    0.0               0.0                    0.0   \n",
       "14                    0.0               0.0                    0.0   \n",
       "15                    0.0               0.0                    0.0   \n",
       "16                    0.0               0.0                    0.0   \n",
       "\n",
       "    month_sale_shop_lag_2  month_sale_lag_3  month_sale_item_lag_3  \\\n",
       "12                    0.0               0.0                    0.0   \n",
       "13                    0.0               0.0                    0.0   \n",
       "14                    0.0               0.0                    0.0   \n",
       "15                    0.0               0.0                    0.0   \n",
       "16                    0.0               0.0                    0.0   \n",
       "\n",
       "    month_sale_shop_lag_3  month_sale_lag_12  month_sale_item_lag_12  \\\n",
       "12                    0.0                0.0                     0.0   \n",
       "13                    0.0                0.0                     0.0   \n",
       "14                    0.0                0.0                     0.0   \n",
       "15                    0.0                0.0                     0.0   \n",
       "16                    0.0                0.0                     0.0   \n",
       "\n",
       "    month_sale_shop_lag_12  \n",
       "12                  5411.0  \n",
       "13                  5820.0  \n",
       "14                     0.0  \n",
       "15                     0.0  \n",
       "16                     0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 49.2 ms\n"
     ]
    }
   ],
   "source": [
    "lag_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. all item cnt\n",
    "2. all shop cnt\n",
    "3. KNN features\n",
    "4. Mean encoding\n",
    "5. time series analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train / valid / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save `date_block_num`, as we can't use them as features, but will need them to split the dataset into parts \n",
    "dates = lag_df['date_block_num']\n",
    "valid_block = 33\n",
    "test_block = 34\n",
    "\n",
    "dates_train = dates[dates <  valid_block]\n",
    "dates_valid  = dates[dates == valid_block]\n",
    "dates_test = dates[dates == test_block]\n",
    "\n",
    "X_train = lag_df.loc[dates <  valid_block].drop(to_drop_cols, axis=1).values\n",
    "y_train = lag_df.loc[dates <  valid_block, 'month_sale'].values.clip(0,20)\n",
    "\n",
    "valid = lag_df.loc[dates == valid_block]\n",
    "valid = test.merge(valid, how='left').fillna(0).drop('ID', axis=1)\n",
    "X_valid =  valid.drop(to_drop_cols, axis=1).values\n",
    "y_valid =  valid['month_sale'].values.clip(0,20)\n",
    "\n",
    "X_full_train = lag_df.loc[dates <  test_block].drop(to_drop_cols, axis=1).values\n",
    "y_full_train = lag_df.loc[dates <  test_block, 'month_sale'].values.clip(0,20)\n",
    "X_test = lag_df.loc[dates == test_block].drop(to_drop_cols, axis=1).values\n",
    "#X_test = test.merge(lag_df.loc[dates == test_block], how='left').fillna(0).drop(to_drop_cols + ['ID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define this competition metric as a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First level models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. half: 1,2,3,6,9,12\n",
    "2. 1/3: 1,2,3,12\n",
    "3. half2: 1-5, 12\n",
    "4. 1/3_2: 1,2,3,4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LinearRegression\n",
    "    1. yonly\n",
    "        1. 1-12: 0.933236273624 => 1.09279\n",
    "        2. half: 0.931571168513 - 16.4 s\n",
    "        3. 1/3: 0.9262253239 - 11.5 s\n",
    "    2. y + shop_y + 1/3: 0.925771859478 - 30 s\n",
    "    3. item_y: 0.924365311084 - 40.8 s\n",
    "    4. clip_month_sale: 0.902686261502 - 47.1 s => 1.03034\n",
    "    5. clip(0,40): 0.908622732715 - 51 s\n",
    "- ElasticNet\n",
    "    1. yonly\n",
    "        1. 1-12: 0.912161949243 => 1.04670\n",
    "        2. half: 0.91242207741 - 21.7 s\n",
    "        3. 1/3: 0.910106878399 - 12.3 s\n",
    "    2. y + shop_y + 1/3: 0.908298623397 - 1min\n",
    "    3. item_y: 0.918947709243 - 1min 24s\n",
    "    4. clip_month_sale: 0.997504443555 - 53.8 s => 1.12730\n",
    "    5. clip(0,40): 0.986036525298 - 54.2 s\n",
    "- RandomForestRegressor\n",
    "    1. yonly \n",
    "        1. 1-12(max_depth=3): 0.980893498007\n",
    "        2. half(max_depth=10): 0.903594473573 - 3min 19s\n",
    "        3. 1/3: 0.907014417171 - 2min 40s, 0.906545092257 - 2min 44s(seed)\n",
    "    2. y + shop_y + 1/3: 0.904931700085 - 4min 56s\n",
    "    3. item_y: 0.900006389736 - 6min 21s\n",
    "    4. clip_month_sale\n",
    "        1. n5d10: 0.884558830043 - 6min 54s\n",
    "        2. n50\n",
    "            - d13: 0.880630637901 - 58min 53s\n",
    "            - d14: 0.880980458672 - 1h 1min 33s\n",
    "            - d15: 0.880768923211 - 1h 4min 59s\n",
    "            - d16: 0.881246216635 - 1h 8min 3s\n",
    "        3. n1dNone: 1.08458987675 - 4min 31s\n",
    "    5. clip(0,40): 0.888263907278 - 6min 33s\n",
    "- ExtraTreesRegressor\n",
    "    1. yonly\n",
    "        1. 1-12(n=10, max_depth=5): 0.980940782649\n",
    "        2. half(max_depth=20): 0.907416246054 - 2min 6s\n",
    "        3. 1/3: 0.907362455722 - 1min 35s, 0.905973938144 - 1min 44s, 0.907614968974 - 1min 51s(seed)\n",
    "    3. item_y: 0.901501525093 - 7min 42s\n",
    "    4. clip_month_sale: 0.886585196886 - 9min 6s (not anymore.. only RF)\n",
    "        - n50d13: 0.883138230251 - 48min 6s\n",
    "- lightgbm\n",
    "    1. yonly\n",
    "        1. 1-12: 0.893098000611 => 1.02475\n",
    "        2. half: 0.894044244386 - 4min 27s\n",
    "        3. 1/3: 0.893822409009 - 3min 36s\n",
    "    3. item_y: 0.886242950874 - 5min 43s => 1.01865\n",
    "    4. clip_month_sale\n",
    "        - ** 1/3: 0.878756133684 - 5min 3s => 1.01201 **\n",
    "        - 1/3_2:  0.878191759896 - 4min 51s => 1.01532\n",
    "        - half:   0.875355556599 - 5min 51s => 1.01262\n",
    "        - half2:  0.876777727805 - 6min 6s => 1.01255\n",
    "        \n",
    "    5. clip(0,40): 0.878402461649 - 4min 55s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation score를 믿을만하다고 생각했었는데 feature변경하면서 하다보니 안맞는 부분이 있군..\n",
    "- 카테고리 정보 활용?\n",
    "- 이름 정보 활용?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33 ms\n"
     ]
    }
   ],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.clip(y_true, 0, 20), np.clip(y_pred, 0, 20)))\n",
    "\n",
    "def get_valid_rmse(reg):\n",
    "    reg.fit(X_train, y_train)\n",
    "    pred = reg.predict(X_valid)\n",
    "    print(rmse(pred, y_valid))\n",
    "    \n",
    "def get_valid_rmse2(reg, i):\n",
    "    reg.fit(X_train, y_train)\n",
    "    pred = reg.predict(X_valid)\n",
    "    print(i + ': ' + str(rmse(pred, y_valid)))\n",
    "    \n",
    "def get_prediction(reg):\n",
    "    reg.fit(X_full_train, y_full_train)\n",
    "    pred = reg.predict(X_test)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest 실험 결과 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n-1 d-5: 0.907364982577\n",
    "- n-1 d-8: 0.89459729871\n",
    "- n-1 d-10: 0.895443025682\n",
    "- n-1 d-13: 0.907934495971\n",
    "- n-1 d-15: 0.922931800723\n",
    "- n-2 d-5: 0.905816024133\n",
    "- n-2 d-8: 0.892378300441\n",
    "- n-2 d-10: 0.891449670099\n",
    "- n-2 d-13: 0.894940465977\n",
    "- n-2 d-15: 0.906524026616\n",
    "- n-3 d-5: 0.904804930646\n",
    "- n-3 d-8: 0.891574099542\n",
    "- n-3 d-10: 0.888751033308\n",
    "- n-3 d-13: 0.890498987202\n",
    "- n-3 d-15: 0.897281007082\n",
    "- n-4 d-5: 0.904425711382\n",
    "- n-4 d-8: 0.891026194803\n",
    "- n-4 d-10: 0.886066862395\n",
    "- n-4 d-13: 0.887052497829\n",
    "- n-4 d-15: 0.890746942068\n",
    "- n-5 d-5: 0.904218191743\n",
    "- n-5 d-8: 0.889983926703\n",
    "- n-5 d-10: 0.884558830043\n",
    "- n-5 d-13: 0.885515521105\n",
    "- n-5 d-15: 0.88867127083\n",
    "- n-10 d-5: 0.903706002099\n",
    "- n-10 d-8: 0.889455372439\n",
    "- n-10 d-10: 0.883724366696\n",
    "- n-10 d-13: 0.882571987825\n",
    "- n-10 d-15: 0.885643626759\n",
    "- n-20 d-5: 0.903612684362\n",
    "- n-20 d-8: 0.888859116109\n",
    "- n-20 d-10: 0.883396754691\n",
    "- n-20 d-13: 0.881203453387\n",
    "- n-20 d-15: 0.881972022241\n",
    "\n",
    "time: 3h 47min 29s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple ensembling structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ensemble two model\n",
    "    1. Linear Regression(0.90268626150226106), lightgbm(0.87875613368405925) =>\n",
    "        1. last 3\n",
    "            1. Linear Regression: 0.879674\n",
    "            2. lightgbm: 0.947700\n",
    "            3. Random Forest: 0.881135\n",
    "        2. last 6\n",
    "            1. Linear Regression: 0.877625\n",
    "            2. lightgbm: 0.959168\n",
    "            3. Random Forest: 0.878719\n",
    "        3. last 6 + X_train\n",
    "            1. Linear Regression: 0.876767\n",
    "            2. lightgbm: 0.882532\n",
    "            3. Random Forest: 0.877934\n",
    "            4. ElasticNet(alpha=0.01): 0.888654\n",
    "- ensemble three model\n",
    "    1. Linear Regression, lightgbm, KnnRegressor\n",
    "        - winner in two models\n",
    "- ensemble five models\n",
    "    1. Linear Regression, ElasticNet, lightgbm, Random Forest, KnnRegressor\n",
    "        - ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "# Save `date_block_num`, as we can't use them as features, but will need them to split the dataset into parts \n",
    "dates = lag_df['date_block_num']\n",
    "valid_block = 33\n",
    "test_block = 34\n",
    "\n",
    "dates_train = dates[dates <  valid_block]\n",
    "dates_valid  = dates[dates == valid_block]\n",
    "dates_test = dates[dates == test_block]\n",
    "\n",
    "X_train = lag_df.loc[dates <  valid_block].drop(to_drop_cols, axis=1)\n",
    "y_train = lag_df.loc[dates <  valid_block, 'month_sale'].values.clip(0,20)\n",
    "\n",
    "valid = lag_df.loc[dates == valid_block]\n",
    "valid = test.merge(valid, how='left').fillna(0).drop('ID', axis=1)\n",
    "X_valid =  valid.drop(to_drop_cols, axis=1)\n",
    "y_valid =  valid['month_sale'].values.clip(0,20)\n",
    "\n",
    "X_full_train = lag_df.loc[dates <  test_block].drop(to_drop_cols, axis=1)\n",
    "y_full_train = lag_df.loc[dates <  test_block, 'month_sale'].values.clip(0,20)\n",
    "X_test = lag_df.loc[dates == test_block].drop(to_drop_cols, axis=1).values\n",
    "#X_test = test.merge(lag_df.loc[dates == test_block], how='left').fillna(0).drop(to_drop_cols + ['ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90268626150226106"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 45.3 s\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train.values, y_train)\n",
    "pred_lr = lr.predict(X_valid.values)\n",
    "\n",
    "rmse(pred_lr, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87875613368405925"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4min 52s\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':1, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':0 \n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "lgb = lightgbm.train(lgb_params, lightgbm.Dataset(X_train.values, label=y_train), 100)\n",
    "pred_lgb = lgb.predict(X_valid)\n",
    "\n",
    "rmse(lgb_pred, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.63 s\n"
     ]
    }
   ],
   "source": [
    "pred_lgb = lgb.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.59 ms\n"
     ]
    }
   ],
   "source": [
    "X_test_level2 = np.c_[pred_lr, pred_lgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 947 ms\n"
     ]
    }
   ],
   "source": [
    "#원래는 27~32였는데 시간이 오래걸릴거 같아서 줄임\n",
    "level2_date_blocks = [27,28,29,30,31,32]\n",
    "dates_train_level2 = dates_train[dates_train.isin(level2_date_blocks)]\n",
    "\n",
    "# That is how we get target for the 2nd level dataset\n",
    "y_train_level2 = y_train[dates_train.isin(level2_date_blocks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "time: 30min 47s\n"
     ]
    }
   ],
   "source": [
    "# And here we create 2nd level feeature matrix, init it with zeros first\n",
    "X_train_level2 = np.zeros([y_train_level2.shape[0], 2])\n",
    "\n",
    "# Now fill `X_train_level2` with metafeatures\n",
    "for cur_block_num in level2_date_blocks:\n",
    "    \n",
    "    print(cur_block_num)\n",
    "    \n",
    "    '''\n",
    "        1. Split `X_train` into parts\n",
    "           Remember, that corresponding dates are stored in `dates_train` \n",
    "        2. Fit linear regression \n",
    "        3. Fit LightGBM and put predictions          \n",
    "        4. Store predictions from 2. and 3. in the right place of `X_train_level2`. \n",
    "           You can use `dates_train_level2` for it\n",
    "           Make sure the order of the meta-features is the same as in `X_test_level2`\n",
    "    '''\n",
    "    \n",
    "    #  YOUR CODE GOES HERE\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train[dates_train < cur_block_num].values, y_train[dates_train < cur_block_num])\n",
    "    pred_lr_level2 = lr.predict(X_train[dates_train == cur_block_num].values)\n",
    "    \n",
    "    lgb = lightgbm.train(lgb_params, lightgbm.Dataset(X_train[dates_train < cur_block_num], label=y_train[dates_train < cur_block_num]), 100)\n",
    "    pred_lgb_level2 = lgb.predict(X_train[dates_train == cur_block_num].values)\n",
    "    \n",
    "    X_train_level2[dates_train_level2.isin([cur_block_num]), 0] = pred_lr_level2.copy()\n",
    "    X_train_level2[dates_train_level2.isin([cur_block_num]), 1] = pred_lgb_level2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a0d938f60>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0c3c5d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "plt.scatter(X_train_level2[:,0], X_train_level2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.15 s\n"
     ]
    }
   ],
   "source": [
    "X_train_plus_level2 = np.c_[X_train[dates_train.isin(level2_date_blocks)].values, X_train_level2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7981200, 16)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.07 ms\n"
     ]
    }
   ],
   "source": [
    "X_train_plus_level2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "meta_model = lightgbm.train(lgb_params, lightgbm.Dataset(X_train_plus_level2, label=y_train_level2), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3min 50s\n"
     ]
    }
   ],
   "source": [
    "meta_model = RandomForestRegressor(max_depth=5)\n",
    "\n",
    "meta_model.fit(X_train_plus_level2, y_train_level2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 57.8 ms\n"
     ]
    }
   ],
   "source": [
    "valid_plus = np.c_[X_valid.values, stacked_valid_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.01, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 57.6 s\n"
     ]
    }
   ],
   "source": [
    "meta_model = ElasticNet(alpha=0.01)\n",
    "\n",
    "meta_model.fit(X_train_plus_level2, y_train_level2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rmse for stacking is 0.360417\n",
      "Test  rmse for stacking is 0.888654\n",
      "time: 370 ms\n"
     ]
    }
   ],
   "source": [
    "train_preds = meta_model.predict(X_train_plus_level2)\n",
    "rmse_train_stacking = rmse(y_train_level2, train_preds)\n",
    "\n",
    "valid_preds = meta_model.predict(valid_plus)\n",
    "rmse_valid_stacking = rmse(y_valid, valid_preds)\n",
    "\n",
    "print('Train rmse for stacking is %f' % rmse_train_stacking)\n",
    "print('Test  rmse for stacking is %f' % rmse_valid_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO: pred만 보내서 submission 만들도록 함수 만들기\n",
    "\n",
    "pred = ensemble_pred\n",
    "dd = lag_df[dates == test_block]\n",
    "dd.month_sale = pred\n",
    "dd = dd[['shop_id', 'item_id', 'month_sale']]\n",
    "dd = dd.rename(columns={'month_sale':'item_cnt_month'})\n",
    "make_submission(dd, 'ensemble_lr_lgb_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell automatically submits the submission file to kaggle. However, it should be carefully executed because the submitting opportunities are limited.\n",
    "- remove '#' before submitting\n",
    "- add a meaningful message to a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!kaggle competitions submit -c competitive-data-science-final-project -f ./submission/lgb_onetofour_data.csv -m \"lgb with clipped train data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check public score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submissions -c competitive-data-science-final-project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sure, it scores better with more data han less data. One more thing I want to try is using full data in training and validating with only test data id combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- clipping [0, 20] in training (done)\n",
    "- using category, shop information, name(translated in discussion)\n",
    "- Check one hot encoding and label encoding\n",
    "- using scipy sparse matrix representation\n",
    "- elaborate valdiation scheme not only using 33 to valdiate(how about 5 folds moving window?) => 계산 시간이 너무 많이 걸릴거같은데..ㅠㅠ\n",
    "- add feature(season?) 해볼까.. \n",
    "- can I use scipy.sparse here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
