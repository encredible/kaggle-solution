{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have to install ipython-autotime using 'pip install ipython-autotime'\n",
    "%load_ext autotime\n",
    "\n",
    "import gc\n",
    "import IPython.display\n",
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# in this project, the metric is rmse, not mse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# SVR and KNeighborsRegressor is too slow to apply this data\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#TODO: sklearn AdaBoost, GradientBoosting 사용\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "seed = 180718\n",
    "\n",
    "# lag 양을 여기서 결정\n",
    "shift_range = [1,2,3,12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.76 s\n"
     ]
    }
   ],
   "source": [
    "sales = pd.read_csv('./dataset/sales_train.csv.gz')\n",
    "shops = pd.read_csv('./dataset/shops.csv')\n",
    "items = pd.read_csv('./dataset/items.csv')\n",
    "#item_cats = pd.read_csv('./dataset/item_categories.csv')\n",
    "test = pd.read_csv(\"./dataset/test.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define a useful function to save a memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.77 ms\n"
     ]
    }
   ],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get base data form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The form should have 'shop_id', 'item_id', 'date_block_num' because the required form of this competition is 'ID' made of 'shop_id' and 'item_id', and 'item_cnt_month'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.59 s\n"
     ]
    }
   ],
   "source": [
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "gb = sales.groupby(index_cols, as_index=False).sum().rename(columns={'item_cnt_day':'month_sale'})\n",
    "\n",
    "del sales\n",
    "\n",
    "# 가격 정보를 사용할 것인지 아직 모름. 사용한다면 살려야 함.\n",
    "gb = gb.drop('item_price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.24 s\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'shop_id': np.sort(shops.shop_id.unique()), 'key':np.zeros(len(shops.shop_id.unique()))})\n",
    "df2 = pd.DataFrame({'item_id': np.sort(items.item_id.unique()), 'key':np.zeros(len(items.item_id.unique()))})\n",
    "df3 = pd.DataFrame({'date_block_num': np.sort(gb.date_block_num.unique()), 'key':np.zeros(len(gb.date_block_num.unique()))})\n",
    "\n",
    "df = df1.merge(df2).merge(df3)\n",
    "\n",
    "del df1, df2, df3, shops\n",
    "\n",
    "df = df.drop('key', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.5 s\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(gb, how='outer').fillna(0)\n",
    "\n",
    "del gb\n",
    "\n",
    "df.head()\n",
    "\n",
    "df = downcast_dtypes(df)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip (0, 20) before making something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 441 ms\n"
     ]
    }
   ],
   "source": [
    "df.month_sale = df.month_sale.values.clip(0,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# montly sale in the shop, item, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "shop_gb_sum = df.groupby(['shop_id', 'date_block_num'], as_index=False).sum()\n",
    "shop_gb_sum = shop_gb_sum.rename(columns={'month_sale':'month_sale_shop_sum'})\n",
    "shop_gb_sum = shop_gb_sum.drop(columns=['item_id'])\n",
    "\n",
    "shop_gb_mean = df.groupby(['shop_id', 'date_block_num'], as_index=False).mean()\n",
    "shop_gb_mean = shop_gb_mean.rename(columns={'month_sale':'month_sale_shop_mean'})\n",
    "shop_gb_mean = shop_gb_mean.drop(columns=['item_id'])\n",
    "\n",
    "item_gb_sum = df.groupby(['item_id', 'date_block_num'], as_index=False).sum()\n",
    "item_gb_sum = item_gb_sum.rename(columns={'month_sale':'month_sale_item_sum'})\n",
    "item_gb_sum = item_gb_sum.drop(columns=['shop_id'])\n",
    "\n",
    "item_gb_mean = df.groupby(['item_id', 'date_block_num'], as_index=False).mean()\n",
    "item_gb_mean = item_gb_mean.rename(columns={'month_sale':'month_sale_item_mean'})\n",
    "item_gb_mean = item_gb_mean.drop(columns=['shop_id'])\n",
    "\n",
    "category = items.drop(columns=['item_name'], axis=1)\n",
    "category = category.rename(columns={'item_category_id':'category_id'})\n",
    "\n",
    "item_sum_with_cat_gb = item_gb_sum.merge(category, how='left')\n",
    "\n",
    "category_gb_sum = item_sum_with_cat_gb.groupby(['category_id', 'date_block_num'], as_index=False).sum()\n",
    "category_gb_sum = category_gb_sum.rename(columns={'month_sale_item_sum':'month_sale_category_sum'})\n",
    "category_gb_sum = category_gb_sum.drop(columns=['item_id'], axis=1)\n",
    "\n",
    "category_gb_mean = item_sum_with_cat_gb.groupby(['category_id', 'date_block_num'], as_index=False).mean()\n",
    "category_gb_mean = category_gb_mean.rename(columns={'month_sale_item_sum':'month_sale_category_mean'})\n",
    "category_gb_mean = category_gb_mean.drop(columns=['item_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(shop_gb_sum, how='left').fillna(0)\n",
    "df = df.merge(shop_gb_mean, how='left').fillna(0)\n",
    "\n",
    "df = df.merge(item_gb_sum, how='left').fillna(0)\n",
    "df = df.merge(item_gb_mean, how='left').fillna(0)\n",
    "\n",
    "df = df.merge(category, how='left').fillna(0)\n",
    "df = df.merge(category_gb_sum, how='left').fillna(0)\n",
    "df = df.merge(category_gb_mean, how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 384 ms\n"
     ]
    }
   ],
   "source": [
    "del shop_gb_sum, shop_gb_mean, item_gb_sum, item_gb_mean, category_gb_sum, category_gb_mean, category, item_sum_with_cat_gb, items\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# montly sale in the item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.44 s\n"
     ]
    }
   ],
   "source": [
    "#12개월 전체를 할 수도 있고 일부를 할 수도 있다. 난 여기서 일부만 사용\n",
    "#ensembling에선 1~5,12를 사용\n",
    "\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num', 'category_id']\n",
    "\n",
    "cols_to_rename = list(df.columns.difference(index_cols)) \n",
    "df = downcast_dtypes(df)\n",
    "lag_df = df.copy()\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef9b3a19b1645a381488f227949148f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time: 13min 38s\n"
     ]
    }
   ],
   "source": [
    "for month_shift in tqdm_notebook(shift_range):\n",
    "    train_shift = lag_df[index_cols + cols_to_rename].copy()\n",
    "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "    \n",
    "    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "    train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "    lag_df = lag_df.merge(train_shift, how='outer')\n",
    "    \n",
    "    del train_shift, foo\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:2540: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "# 이유는 모르겠는데 끝나고 나면 lag_df에서 index column들이 64비트로 변경됨\n",
    "lag_df[index_cols] = downcast_dtypes(lag_df[index_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Abort unnecessary data in lag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "lag_df = lag_df[12 <= lag_df.date_block_num]\n",
    "lag_df = lag_df[lag_df.date_block_num <= 34]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save and Load lag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.1 ms\n"
     ]
    }
   ],
   "source": [
    "#압축하면서 저장하는게 너무 오래걸린다. 나중에 시간 있을 때 한번 돌려보자.\n",
    "#lag_df.to_csv(\"lag_df.csv.gz\", index=False, compression='gzip')\n",
    "\n",
    "# lag_df = pd.read_csv(\"lag_df.csv.gz\")\n",
    "# lag_df = downcast_dtypes(lag_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train / valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32.9 ms\n"
     ]
    }
   ],
   "source": [
    "dates = lag_df['date_block_num']\n",
    "fit_cols = [col for col in lag_df.columns if col[-1] in [str(item) for item in shift_range]] \n",
    "to_drop_cols = list(set(list(lag_df.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "valid_block = 33\n",
    "\n",
    "dates_train = dates[dates <  valid_block]\n",
    "dates_valid  = dates[dates == valid_block]\n",
    "\n",
    "X_train = lag_df.loc[dates <  valid_block].drop(to_drop_cols, axis=1).to_sparse()\n",
    "y_train = lag_df.loc[dates <  valid_block, 'month_sale'].values.clip(0,20)\n",
    "\n",
    "valid = lag_df.loc[dates == valid_block]\n",
    "valid = test.merge(valid, how='left').fillna(0).drop('ID', axis=1).to_sparse()\n",
    "X_valid =  valid.drop(to_drop_cols, axis=1).to_sparse()\n",
    "y_valid =  valid['month_sale'].values.clip(0,20)\n",
    "\n",
    "del valid, lag_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make full train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.98 ms\n"
     ]
    }
   ],
   "source": [
    "# test_block = 34\n",
    "\n",
    "# dates_full_train = dates[dates < test_block]\n",
    "# dates_test = dates[dates == test_block]\n",
    "\n",
    "# X_full_train = lag_df.loc[dates <  test_block].drop(to_drop_cols, axis=1)\n",
    "# y_full_train = lag_df.loc[dates <  test_block, 'month_sale'].values.clip(0,20)\n",
    "# X_test = lag_df.loc[dates == test_block].drop(to_drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define this competition metric as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 35.8 ms\n"
     ]
    }
   ],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.clip(y_true, 0, 20), np.clip(y_pred, 0, 20)))\n",
    "\n",
    "def get_valid_rmse(reg):\n",
    "    reg.fit(X_train.values, y_train)\n",
    "    pred = reg.predict(X_valid.values)\n",
    "    return rmse(pred, y_valid)\n",
    "\n",
    "def get_prediction(reg):\n",
    "    reg.fit(X_full_train.values, y_full_train)\n",
    "    pred = reg.predict(X_test.values)\n",
    "    return pred\n",
    "\n",
    "def make_submission_from_prediction(pred, filename):\n",
    "    sub = lag_df[dates == test_block]\n",
    "    sub = sub.rename(columns={'month_sale':'item_cnt_month'})\n",
    "    sub = sub[['shop_id', 'item_id', 'month_sale']]\n",
    "    make_submission(sub, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First level models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89983426883881978"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7min 56s\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "get_valid_rmse(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet = ElasticNet()\n",
    "get_valid_rmse(enet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb = LGBMRegressor(random_state=seed)\n",
    "get_valid_rmse(lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8821269853328018"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 43min 3s\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=20, max_depth=13, random_state=seed)\n",
    "get_valid_rmse(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop_id: 0.005938857500999187\n",
      "item_id: 0.021326064336808163\n",
      "category_id: 0.007972726863236742\n",
      "month_sale_lag_1: 0.6465714500061555\n",
      "month_sale_category_mean_lag_1: 0.008624141447710783\n",
      "month_sale_category_sum_lag_1: 0.007536008250074994\n",
      "month_sale_item_mean_lag_1: 0.039725975588308204\n",
      "month_sale_item_sum_lag_1: 0.03251625320541881\n",
      "month_sale_shop_mean_lag_1: 0.006472418298511968\n",
      "month_sale_shop_sum_lag_1: 0.0070434549731058504\n",
      "month_sale_lag_2: 0.03364581297228696\n",
      "month_sale_category_mean_lag_2: 0.008653950221609997\n",
      "month_sale_category_sum_lag_2: 0.008892765429332431\n",
      "month_sale_item_mean_lag_2: 0.008119195875594955\n",
      "month_sale_item_sum_lag_2: 0.007996687915974625\n",
      "month_sale_shop_mean_lag_2: 0.006869937708972531\n",
      "month_sale_shop_sum_lag_2: 0.0058250433257976495\n",
      "month_sale_lag_3: 0.04117458427741591\n",
      "month_sale_category_mean_lag_3: 0.00802149236251935\n",
      "month_sale_category_sum_lag_3: 0.010712345698485195\n",
      "month_sale_item_mean_lag_3: 0.004117669543735631\n",
      "month_sale_item_sum_lag_3: 0.0038548439009915684\n",
      "month_sale_shop_mean_lag_3: 0.0038313732530357893\n",
      "month_sale_shop_sum_lag_3: 0.0035420654092734065\n",
      "month_sale_lag_12: 0.004775491533169776\n",
      "month_sale_category_mean_lag_12: 0.013202608879856751\n",
      "month_sale_category_sum_lag_12: 0.007057560002099656\n",
      "month_sale_item_mean_lag_12: 0.0020956732202855473\n",
      "month_sale_item_sum_lag_12: 0.0023415666860874713\n",
      "month_sale_shop_mean_lag_12: 0.014805446457966016\n",
      "month_sale_shop_sum_lag_12: 0.016736534855178606\n",
      "time: 3.3 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_train.columns.values)):\n",
    "    print(str(X_train.columns.values[i]) + \": \" + str(rf.feature_importances_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87428755"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 37min 59s\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth=10, learning_rate=0.03, random_state=seed)\n",
    "get_valid_rmse(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_submission_from_prediction(get_prediction(rf), 'rf_n20_m13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission_from_prediction(get_prediction(xgb), 'xgb_m10_l3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_params = {\n",
    "#                'feature_fraction': 0.75,\n",
    "#                'metric': 'rmse',\n",
    "#                'nthread':1, \n",
    "#                'min_data_in_leaf': 2**7, \n",
    "#                'bagging_fraction': 0.75, \n",
    "#                'learning_rate': 0.03, \n",
    "#                'objective': 'mse', \n",
    "#                'bagging_seed': 2**7, \n",
    "#                'num_leaves': 2**7,\n",
    "#                'bagging_freq':1,\n",
    "#                'verbose':0 \n",
    "#               }\n",
    "\n",
    "# lgb = lightgbm.train(lgb_params, lightgbm.Dataset(X_train.values, label=y_train), 100)\n",
    "# pred_lgb = lgb.predict(X_valid)\n",
    "# rmse(pred_lgb, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make utilities to submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function makes codes simple, so it's good to make these functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.97 ms\n"
     ]
    }
   ],
   "source": [
    "def make_submission_df(all_prediction):\n",
    "    df = test.merge(all_prediction, on=[\"shop_id\", \"item_id\"], how=\"left\")[[\"ID\", \"item_cnt_month\"]]\n",
    "    df[\"item_cnt_month\"] = df[\"item_cnt_month\"].fillna(0).clip(0, 20)    \n",
    "    return df\n",
    "\n",
    "def make_submission_file(df, filename):\n",
    "    df.to_csv(\"./submission/%s.csv\" % filename, index=False)\n",
    "    \n",
    "def make_submission(all_prediction, filename=\"no_name\"):\n",
    "    make_submission_file(make_submission_df(all_prediction), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell automatically submits the submission file to kaggle. However, it should be carefully executed because the submitting opportunities are limited.\n",
    "- remove '#' before submitting\n",
    "- add a meaningful message to a submission\n",
    "- my rule is using a filename for models and a message for data\n",
    "    - ex) filename: rf_n20m13.csv, message: ot-sic-sm-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c competitive-data-science-final-project -f ./submission/rf_n20_m13.csv -m \"ot-sic-sm-20\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check public score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submissions -c competitive-data-science-final-project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
